<!DOCTYPE HTML>
<html><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yiqing Li (李逸清)'s Homepage</title>
  <meta name="author" content="Yiqing Li">
  <meta name="description" content="Yiqing Li's Homepage">
  <meta name="keywords" content="Yiqing Li,李逸清,homepage,主页,computer vision,Peking University,image generation,texture synthesis,3D reconstruction">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" href="data:image/svg+xml,<svg xmlns=%22http://www.w3.org/2000/svg%22 viewBox=%220 0 100 100%22><text y=%22.9em%22 font-size=%2290%22>😃</text></svg>">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yiqing Li (李逸清)</name>
              </p>
              <p style="text-align:center">
                Email: liyiqing_cs[at]163.com/206001870[at]nbu.edu.cn
              </p><p style="text-align:center">
                 &nbsp;&nbsp;<a href="https://github.com/sayoriaaa">Github</a>&nbsp;&nbsp;<a href="assets/CV.pdf">CV</a>
                <!--&nbsp;&nbsp;<a href="https://scholar.google.com/citations?user=liyiqing_cs">Google Scholar</a>-->&nbsp;&nbsp;<a href="https://x.com/sayoriaaa">Twitter</a>&nbsp;&nbsp;<a href="https://www.zhihu.com/people/underdog-61-32">知乎</a>
              </p>
              <p>

                I am Yiqing Li (李逸清). My study interests lie in Computer Graphics and Computer Vision.
                <br>
              </p>

              <p>
                I obtained my bachelor degree of Computer Science and Technology from Ningbo University, China, 2024.
              </p>

            </td>
            <td style="padding:15% 7% 7% 7%;width:40%;max-width:40%">
              <a href="images/Yiqing_Li_Cartoon.jpeg"><img style="width:100%;max-width:100%" alt="profile photo" src="images/Yiqing_Li_Cartoon.jpeg" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
          <td style="padding:20px;width:100%;vertical-align:middle">
            <heading>News!<!--🔥--></heading>
            <li>2024.07.30: FINALLY! Our paper: <i>Evaluating Domain Translation Approaches for Drone-Based Geo-Localization in Adverse Weather</i> is accepted by ACM MM 2024 Workshop on <a href="https://www.zdzheng.xyz/ACMMM2024Workshop-UAV/">UAVM</a>.</li>
            <li>2024.07: Won 6th of 22 teams in ACM MM 2024 Competition: <a href="https://codalab.lisn.upsaclay.fr/competitions/18770#results">Multimedia Drone Satellite Matching Challenge In Multiple-environment</a>   </li>
            <li>2024.06: My Bachelor Thesis is evaluated as Excellent Thesis (Top 20%) of EECS Faculty.</li>
            <!-- <li>2024.03.28: Participated paddle's <a href="https://pfcclab.github.io/posts/starter-camp">Starter Camp</a> (remote). Work on Complex OP.</li> -->
            <li>2024.03<!--.15-->: Starting my research intern @ ZRIT. Work on UAV related computer vison tasks. </li>
          </td>
          </tr>
      </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Publications</heading>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

          <tr></tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
            <a href="images/paper-acmmmw/figure.png"><img style="width:120%;max-width:120%" alt="damo" src="images/paper-acmmmw/figure.png" class="hoverZoomLink"></a>
        </td>
          <td style="padding:20px;width:75%;vertical-align:middle">
              <papertitle>Evaluating Domain Translation Approaches for Drone-Based Geo-Localization in Adverse Weather</papertitle>
              <br>
              <strong><a href="https://sayoriaaa.github.io/me">Yiqing Li</a></strong>, <a href="https://ieeexplore.ieee.org/author/211939848888874">Shuke He</a>, <a href="https://www.linkedin.cn/incareer/in/%E6%99%A8-%E9%87%91-4149a4197">Chen Jin*</a>
              <br>
              <em> ACM MM 2024 Workshop on <a href="https://www.zdzheng.xyz/ACMMM2024Workshop-UAV/">UAVM</a></em>
              <br>
              <strong><font color=red>Rating: 5 5 8 </font></strong>
              <br>
              <a href="assets/ACMMMW24.pdf">[Paper]</a> 
              <a href="https://github.com/sayoriaaa/UAVM24-solution">[Code]</a>
              <br>
              <p>Technical report of our solution for ACM MM 2024 Competition: <a href="https://codalab.lisn.upsaclay.fr/competitions/18770#results">Multimedia Drone Satellite Matching Challenge In Multiple-environment</a>.</p>

              <details>
                <summary>Abstract</summary>
                <ol>
                  <p>
                    The UAVs in Multimedia (UAVM) 2024 competition aims to improve the performance of Drone-based Geo-localization task under extreme weather. On the task, we found the simple augmentation on training set can significant improve performance with zero-cost and won the 6th Place among 22 teams on this competition. Furthermore, based on our observations, we propose a domain translation framework to further enhance the performance of any model. We transfer images from a multi-weather domain to a normal domain using GAN and introduce FFM to further reduce computational costs. Our experiments revealed that while this strategy indeed improves image quality, it does not translate into improved recognition accuracy. Thus, while our strategy is supported by experimental evidence, practical methods for achieving performance improvement remain elusive. We hope this report provides valuable insights for developers and researchers in this field.
                  </p>
                </ol>
              </details>
          </td>
      </tr>


      </tbody></table> 


      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Projects</heading>
        </td>
      </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

      <tr></tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
        <a href="images/L0.png"><img style="width:120%;max-width:120%" alt="damo" src="images/L0.png" class="hoverZoomLink"></a>
    </td>
      <td style="padding:20px;width:75%;vertical-align:middle">
          <papertitle>Feature-preserved Mesh Denoising via Sparse Optimization </papertitle>
          <br>
          Supervised by <a href="https://xzfang.top">Lect. Xianzhong Fang</a>
          <br>
          <em><strong>Ningbo University</strong> degree project</em> 
          <br>
          <strong><font color=red>Top 20% Bachelor Thesis </font></strong>
          <br>
          <a href="assets/BachelorThesis.pdf">[Thesis]</a> 
          <a href="https://github.com/sayoriaaa/SMD">[Code]</a>  
          <a href="assets/BachelorThesisSlide.pdf">[Slide]</a>
          <a href="assets/BachelorThesisSupplements.zip">[Supplements]</a>
          <br>
          <p>
            Reproducing L0 mesh denosing method via Eigen. Proposing a time-efficient approach to achieve 100x speed up. Conducting a CUDA implementation to make L0 method nearly as fast as filtering based method.  
          </p>

            2023.06-2024.06
          </p>
          <details>
            <summary>Abstract</summary>
            <ol>
              <p>
                In the field of geometric processing, mesh denoising plays an important role. Meshes obtained from 3D reconstruction often contain noise that cannot meet requirements and thus require mesh denoising as a post-processing step. Feature-preserving mesh denoising algorithms aim to remove noise while preserving features and are considered state-of-the-art in mesh denoising. However, feature-preserving mesh denoising algorithms based on sparse optimization are superior in performance but time-consuming.
              </p>
              <p>
                This paper investigates feature-preserving mesh denoising algorithms, analyzes representative works and evaluation metrics in this direction, and focuses on the L0 method for algorithm reproduction and experimentation. An efficient optimization scheme is proposed around the L0 method, along with a parallelized implementation, to improve efficiency.
              </p>
              <p>
                The main contributions of this paper are as follows:

                <li>Independently reproducing the L0 method and conducting extensive related experiments.</li>
                <li>Proposing different optimization approaches to address the slow solving speed of optimization-based methods and conducting experiments, ultimately presenting a concise and effective optimization solution.</li>
                <li>Designing and implementing a parallelized L0 algorithm based on 2, enabling efficient feature-preserving denoising of medium to large-scale meshes.</li>
              </p>
            </ol>
          </details>
      </td>
  </tr>
      
  
  </tbody></table> 



      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Experiences</heading>
        </td>
      </tr>
    </tbody></table>
    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

      

      <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
          <a href="images/zrit.png"><img style="width:100%;max-width:100%" alt="damo" src="images/zrit.png" class="hoverZoomLink"></a>
      </td>
      <td width="75%" valign="center">
        <p><strong>2024.03 - 2024.07: Research Intern</strong> in Zhejiang Scientific Research Institute of Transport, Hangzhou, China. Mentored by <a href="https://ieeexplore.ieee.org/author/211939848888874">Shuke He</a> and <a href="https://swsamleo.github.io/wei_shao.github.io/">Dr. Wei Shao</a>. Worked on Drone-based Geo-localization and Multi-Agent 3D Detection.</p>
      </td>

      <tr>
        <td style="padding:20px;width:25%;vertical-align:middle">
            <a href="images/cnitech.png"><img style="width:100%;max-width:100%" alt="damo" src="images/cnitech.png" class="hoverZoomLink"></a>
        </td>
        <td width="75%" valign="center">
          <!--http://manufacture.nimte.cas.cn/about/intro/-->
          <p><strong>2023.05 - 2023.06: Intern</strong> in CV-lab, Ningbo Institude of Material Technology & Engineering, CAS. Supervised by <a href="http://manufacture.nimte.cas.cn/staff_/rsrs/associateResearcher/cvrsr/202203/t20220323_690543.html">Kangkang Song</a>. Worked on the development and deployment of Lite-HRNet based Infrared Pose Estimation. </p>
        </td>

        <tr>
          <td style="padding:20px;width:25%;vertical-align:middle">
              <a href="images/nbu.png"><img style="width:100%;max-width:100%" alt="thu" src="images/nbu.png" class="hoverZoomLink"></a>
          </td>
          <td width="75%" valign="center">
            <p><strong>2022.06 - 2023.03: Participated</strong> at <a href="https://ieeexplore.ieee.org/author/37086288102">Prof. Yuqi Li</a>'s <a href="https://cpregroup.github.io/">CPRE group</a>, Ningbo University. Worked on Physics Augmented Neural Radiance Fields.
            </p>          
            </td>
        </tr>

    </tr>
   
    </tbody></table>


    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr>
      <td style="padding:20px;width:100%;vertical-align:middle">
        <heading>Education</heading>
      </td>
    </tr>
  </tbody></table>
  <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    
    <tr>
      <td style="padding:20px;width:25%;vertical-align:middle">
          <a href="images/nbu.png"><img style="width:100%;max-width:100%" alt="dut" src="images/nbu.png" class="hoverZoomLink"></a>
      </td>
      <td width="75%" valign="center">
        <p><strong>2020.09 - 2024.06:</strong> B.Eng. in Faculty of EECS at Ningbo University, China. Major in Computer Science and Technology.
        </p>
        </td>
    </tr>


 
  </tbody></table>

      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Awards & Scholarships</heading>
          <li><strong>MCM/ICM </strong> 2022:  <strong>Meritorious (<em>top 6% out of 12,100 teams</em>)</strong> <a href="https://www.comap-math.com/mcm/2022Certs/2208278.pdf">Certificate</a> </li> 
          <li><strong>CMC </strong>(Chinese Mathematics Competitions) 2022: <strong>Provincial Second Prize</strong> </li>   
        </td>
      </tr>


      <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <heading>Misc</heading>
 
          <details>     
            <summary>
              English Proficiency
            </summary>
            <li>CET-6 : 518</li>
            <li>Postgraduate Entrance Examination 2024 : 85/100</li>
          </details>

          

          <details>     
            <summary>
              Open Source Activities
            </summary>
            <li>2024.04-2024.06 : Joined <a href="https://github.com/PaddlePaddle/Paddle/issues/61975">Complex Group</a> of Baidu's <a href="https://github.com/PFCCLab/Starter">启航计划</a>, certificate obtained.</li>
            <li>2023.03-2023.07 : Joined <a href="https://github.com/PaddlePaddle/community/blob/master/hackthon_4th/%E3%80%90PaddlePaddle%20Hackathon%204%E3%80%91%20%E6%A8%A1%E5%9E%8B%E5%A5%97%E4%BB%B6%E5%BC%80%E6%BA%90%E8%B4%A1%E7%8C%AE%E4%BB%BB%E5%8A%A1%E5%90%88%E9%9B%86.md#task172">PaddlePaddle Hackathon 4</a> with <a href="https://github.com/GavinBowl">Jiawen Zhou</a> @ ZJU, aim to reproduce <a href="https://github.com/sunset1995/DirectVoxGO">DVGO</a> with paddle to <a href="https://github.com/PaddlePaddle/Paddle3D/tree/develop/contrib/PaddleRendering">PaddleRendering</a>.</li>
          </details>

          <details>     
            <summary>
              Blogs
            </summary>
            <li>My technical blogs on <a href="https://www.zhihu.com/people/underdog-61-32">知乎</a> have 1K+ collections</li>
            <li>one blog about CUDA was reposted by <a href="https://mp.weixin.qq.com/s/9GK8jE7hNF6JbDF7xCmNuA">PaperWeekly</a></li>
          </details>

          <details>     
            <summary>
              GPA
            </summary>
            <li>Undergraduate : 2.69 / 4.0</li>
          </details>

        </td>
      </tr>
    </tbody></table>


      <!-- <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
        <tr>
        <td style="padding:20px;width:100%;vertical-align:middle">
          <a href="images/emm.jpeg"><img style="width:50%;max-width:50%" alt="research" src="images/emm.jpeg" class="hoverZoomLink"></a>
        </td>
      </tr> -->
    <!-- </tbody></table>  -->

    <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

      <tr></tr>
        <td style="padding:20px;width:0%;vertical-align:middle">
      </td>
      <td style="padding:20px;width:100%;vertical-align:middle">
      <hr style="margin-top:0px"> 
      <p>希望能早日上岸🙏🙏🙏，然后</p>   
        <p>Do some cool and solid research! Build stuff that I am proud of!😎</p>
        <p>Last modified: 07/08/2024</p>
        </td>
      </tr>
    </tbody></table>

</body>
</html>
